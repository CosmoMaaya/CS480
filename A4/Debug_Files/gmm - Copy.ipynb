{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.special as ScSc\n",
    "from tqdm import tqdm\n",
    "from scipy.special import logsumexp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSE(X):\n",
    "    x_max = max(X)\n",
    "    diff = [math.exp(x-x_max) for x in X]\n",
    "    sum = x_max + math.log(np.sum(diff))\n",
    "\n",
    "    return sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMM:\n",
    "    \"\"\"\n",
    "    Diagonal Gaussian Mixture Model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k, d, sigma_init = 0.1):\n",
    "        self.num_cluster = k\n",
    "        self.x_dim = d\n",
    "        self.weights = ScSc.softmax(np.random.normal(scale = sigma_init, size=(k,)))\n",
    "        self.means = np.random.normal(scale = sigma_init, size =(k, d))\n",
    "        self.sigmas = np.random.lognormal(sigma=sigma_init, size=(k, d)) # All positive\n",
    "        pi = np.random.rand(k)\n",
    "        self.weights = pi / np.sum(pi)\n",
    "\n",
    "        np.random.seed(0)\n",
    "        self.means = np.random.normal(0, 3, size=(k, d))\n",
    "\n",
    "        np.random.seed(0)\n",
    "        self.sigmas = np.random.rand(k, d) + 0.5\n",
    "    def EM(self, X, max_iter = 500, tol = 1e-5, eps = 1e-10):\n",
    "        \"\"\"\n",
    "        EM Step\n",
    "        \"\"\"\n",
    "        assert X.ndim == 2\n",
    "        n = X.shape[0]\n",
    "        assert X.shape[1] == self.x_dim\n",
    "\n",
    "        loss = []\n",
    "        rlog = np.zeros((n, self.num_cluster))\n",
    "        r = np.zeros((n, self.num_cluster))\n",
    "        for iter in (range(max_iter)):\n",
    "        #     ###########\n",
    "        #     # E Step\n",
    "        #     ###########\n",
    "\n",
    "            for k in range(self.num_cluster):\n",
    "                rlog[:,k] = np.log(self.weights[k] + eps) - 0.5 * np.sum(np.log(self.sigmas[k] + eps)) - 0.5 * np.dot((X-self.means[k]) ** 2, 1/(self.sigmas[k] + eps))\n",
    "            \n",
    "            r_total = logsumexp(rlog, axis=1)\n",
    "            rlog = rlog - r_total[:,None]\n",
    "            loss.append(-np.sum(r_total))\n",
    "\n",
    "            if iter > 1 and abs(loss[iter] - loss[iter-1]) <= tol * abs(loss[iter]):\n",
    "                break\n",
    "            \n",
    "            r = np.exp(rlog)\n",
    "            r_total_i_wise = np.sum(r, axis=0)\n",
    "            self.weights = r_total_i_wise / n\n",
    "            self.means = np.dot(r.T, X) / (r_total_i_wise[:,None] + eps)\n",
    "            self.sigmas = np.dot(r.T, X ** 2) / (r_total_i_wise[:,None] + eps) - self.means ** 2\n",
    "        #     for k in range(self.num_cluster):\n",
    "\n",
    "        #         # Updating rik\n",
    "        #         partition = np.log(self.weights[k]+eps) - 0.5*np.log(self.sigmas[k, :]+eps).sum()\n",
    "        #         s = 1/ (self.sigmas[k, :] + eps)\n",
    "        #         delta = X - self.means[k][np.newaxis, :]\n",
    "        #         exp_term = np.sum(delta * delta * s[np.newaxis, :], axis = -1)\n",
    "        #         rlog[:, k] = -0.5 * exp_term + partition\n",
    "\n",
    "        #     # Normalize\n",
    "        #     rlogsum = []\n",
    "        #     for i in range(n):\n",
    "        #         ri_log = LSE(rlog[i])\n",
    "        #         rlogsum.append(ri_log)\n",
    "        #     rlogsum = np.array(rlogsum)\n",
    "        #     assert rlogsum.shape == (n,)\n",
    "        #     rlogsum = np.array(rlogsum)\n",
    "        #     rlog = rlog - rlogsum[:, np.newaxis]\n",
    "        #     loss = -np.sum(rlogsum)\n",
    "        #     loss_hist.append(loss)\n",
    "\n",
    "            \n",
    "        #     # Convert back to exp form\n",
    "        #     for i in range(n):\n",
    "        #         for k in range(self.num_cluster):\n",
    "        #             r[i, k] = np.exp(rlog[i, k])\n",
    "            \n",
    "        #     if it > 0 and abs(loss_hist[-1] - loss_hist[-2]) <= tol * abs(loss_hist[-1]):\n",
    "        #         break\n",
    "\n",
    "        #     ###########\n",
    "        #     # M Step\n",
    "        #     ###########\n",
    "        #     rsum = np.sum(r, axis = 0)\n",
    "        #     assert rsum.shape == (self.num_cluster,)\n",
    "        #     self.weights = rsum/n\n",
    "\n",
    "        #     for k in range(self.num_cluster):\n",
    "        #         self.means[k, :] = np.sum(r[:, k, np.newaxis] * X, axis = 0) / (rsum[k] + eps)\n",
    "        #         self.sigmas[k, :] = np.sum(r[:, k, np.newaxis] * X * X, axis = 0) / (rsum[k] + eps) - self.means[k, :] * self.means[k, :]\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def sort_weights(self):\n",
    "        \"\"\"\n",
    "        Sort the parameters according to their weights\n",
    "        \"\"\"\n",
    "        order = np.argsort(self.weights)[::-1]\n",
    "        self.weights = self.weights[order]\n",
    "        self.means = self.means[order]\n",
    "        self.sigmas = self.sigmas[order]\n",
    "    \n",
    "    def posterior(self, x):\n",
    "        eps = 1e-8\n",
    "        p = 0\n",
    "        for k in range(self.num_cluster):\n",
    "            det = (2*math.pi) ** 20 * np.prod(self.sigmas[k])\n",
    "            s = 1/ (self.sigmas[k, :] + eps)\n",
    "            delta = x - self.means[k]\n",
    "            exp_term = -0.5 * np.sum(delta * delta * s[np.newaxis, :], axis = -1)\n",
    "            prob = 1/math.sqrt(det+eps) * math.exp(exp_term)\n",
    "            p += self.weights[k]*prob\n",
    "        return p\n",
    "    \n",
    "    # def pdf(self, x):\n",
    "    #     assert x.ndim == 2\n",
    "    #     n = x.shape[0]\n",
    "    #     assert x.shape[1] == self.x_dim\n",
    "        \n",
    "    #     r = np.zeros((n,self.num_cluster))\n",
    "    #     for j in range(self.num_cluster):\n",
    "    #         partition = np.log(self.weights[j]) - 0.5 * np.log(self.sigmas[j,:]).sum()\n",
    "            \n",
    "    #         s = 1 / self.sigmas[j,:]\n",
    "    #         form = x - self.means[j][np.newaxis,:]\n",
    "    #         form = np.sum(form * form * s[np.newaxis,:], axis=-1)\n",
    "    #         r[:,j] = np.exp(-0.5 * form + partition)\n",
    "            \n",
    "    #     return np.sum(r * self.weights[np.newaxis,:], axis=-1)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "gmm_dataset.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\KandaMaya\\Documents\\University\\4A\\CS480\\A4\\Debug_Files\\gmm - Copy.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/KandaMaya/Documents/University/4A/CS480/A4/Debug_Files/gmm%20-%20Copy.ipynb#ch0000003?line=0'>1</a>\u001b[0m data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mloadtxt(\u001b[39m'\u001b[39;49m\u001b[39mgmm_dataset.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, delimiter\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\KandaMaya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\npyio.py:1042\u001b[0m, in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, like)\u001b[0m\n\u001b[0;32m   1040\u001b[0m     fname \u001b[39m=\u001b[39m os_fspath(fname)\n\u001b[0;32m   1041\u001b[0m \u001b[39mif\u001b[39;00m _is_string_like(fname):\n\u001b[1;32m-> 1042\u001b[0m     fh \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mlib\u001b[39m.\u001b[39;49m_datasource\u001b[39m.\u001b[39;49mopen(fname, \u001b[39m'\u001b[39;49m\u001b[39mrt\u001b[39;49m\u001b[39m'\u001b[39;49m, encoding\u001b[39m=\u001b[39;49mencoding)\n\u001b[0;32m   1043\u001b[0m     fencoding \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(fh, \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlatin1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   1044\u001b[0m     line_iter \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(fh)\n",
      "File \u001b[1;32mc:\\Users\\KandaMaya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\_datasource.py:193\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[39mOpen `path` with `mode` and return the file object.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    189\u001b[0m \n\u001b[0;32m    190\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    192\u001b[0m ds \u001b[39m=\u001b[39m DataSource(destpath)\n\u001b[1;32m--> 193\u001b[0m \u001b[39mreturn\u001b[39;00m ds\u001b[39m.\u001b[39;49mopen(path, mode, encoding\u001b[39m=\u001b[39;49mencoding, newline\u001b[39m=\u001b[39;49mnewline)\n",
      "File \u001b[1;32mc:\\Users\\KandaMaya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\_datasource.py:532\u001b[0m, in \u001b[0;36mDataSource.open\u001b[1;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[39mreturn\u001b[39;00m _file_openers[ext](found, mode\u001b[39m=\u001b[39mmode,\n\u001b[0;32m    530\u001b[0m                               encoding\u001b[39m=\u001b[39mencoding, newline\u001b[39m=\u001b[39mnewline)\n\u001b[0;32m    531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 532\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m not found.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: gmm_dataset.csv not found."
     ]
    }
   ],
   "source": [
    "data = np.loadtxt('gmm_dataset.csv', delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing GMM with k = 1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\KandaMaya\\Documents\\University\\4A\\CS480\\A4\\Debug_Files\\gmm - Copy.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/KandaMaya/Documents/University/4A/CS480/A4/Debug_Files/gmm%20-%20Copy.ipynb#ch0000004?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mConstructing GMM with k =\u001b[39m\u001b[39m\"\u001b[39m, k)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/KandaMaya/Documents/University/4A/CS480/A4/Debug_Files/gmm%20-%20Copy.ipynb#ch0000004?line=4'>5</a>\u001b[0m gmm \u001b[39m=\u001b[39m GMM(k, \u001b[39m20\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/KandaMaya/Documents/University/4A/CS480/A4/Debug_Files/gmm%20-%20Copy.ipynb#ch0000004?line=5'>6</a>\u001b[0m loss \u001b[39m=\u001b[39m gmm\u001b[39m.\u001b[39mEM(data)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/KandaMaya/Documents/University/4A/CS480/A4/Debug_Files/gmm%20-%20Copy.ipynb#ch0000004?line=6'>7</a>\u001b[0m losses_overk\u001b[39m.\u001b[39mappend(loss[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/KandaMaya/Documents/University/4A/CS480/A4/Debug_Files/gmm%20-%20Copy.ipynb#ch0000004?line=7'>8</a>\u001b[0m gmms\u001b[39m.\u001b[39mappend(gmm)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "gmms = []\n",
    "losses_overk = []\n",
    "for k in range(1, 11):\n",
    "    print(\"Constructing GMM with k =\", k)\n",
    "    gmm = GMM(k, 20)\n",
    "    loss = gmm.EM(data)\n",
    "    losses_overk.append(loss[-1])\n",
    "    gmms.append(gmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "plt.plot(losses_overk)\n",
    "plt.ylabel(\"Negative Log Likelihood\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.show()\n",
    "print(losses_overk)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose k = 5\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\KandaMaya\\Documents\\University\\4A\\CS480\\A4\\Debug_Files\\gmm - Copy.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/KandaMaya/Documents/University/4A/CS480/A4/Debug_Files/gmm%20-%20Copy.ipynb#ch0000006?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mChoose k = 5\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/KandaMaya/Documents/University/4A/CS480/A4/Debug_Files/gmm%20-%20Copy.ipynb#ch0000006?line=1'>2</a>\u001b[0m chosen_gmm \u001b[39m=\u001b[39m gmms[\u001b[39m4\u001b[39;49m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/KandaMaya/Documents/University/4A/CS480/A4/Debug_Files/gmm%20-%20Copy.ipynb#ch0000006?line=2'>3</a>\u001b[0m chosen_gmm\u001b[39m.\u001b[39msort_weights()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/KandaMaya/Documents/University/4A/CS480/A4/Debug_Files/gmm%20-%20Copy.ipynb#ch0000006?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mWeights:\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print(\"Choose k = 5\")\n",
    "chosen_gmm = gmms[4]\n",
    "chosen_gmm.sort_weights()\n",
    "print(\"Weights:\")\n",
    "print(chosen_gmm.weights)\n",
    "print(\"Means:\")\n",
    "print(chosen_gmm.means)\n",
    "print(\"Covariances:\")\n",
    "print(chosen_gmm.sigmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using GMM on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datasets and reduce by PCA\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "root = './data'\n",
    "train_data = datasets.MNIST(root = root, train= True, transform=None, download=True)\n",
    "test_data = datasets.MNIST(root = root, train= False, transform=None, download=True)\n",
    "\n",
    "train_X = train_data.data\n",
    "train_Y = train_data.targets\n",
    "train_X = np.reshape(train_X, (60000, 784))\n",
    "test_X = test_data.data\n",
    "test_Y = test_data.targets\n",
    "test_X = np.reshape(test_X, (10000, 784))\n",
    "\n",
    "from sklearn.decomposition import PCA \n",
    "\n",
    "d = 40\n",
    "\n",
    "reducer = PCA(n_components=d)\n",
    "reducer.fit(train_X)\n",
    "\n",
    "train_data_reduced = reducer.transform(train_X)\n",
    "test_data_reduced = reducer.transform(test_X)\n",
    "\n",
    "label_set = set(train_Y)\n",
    "train_Y = train_Y.numpy()\n",
    "test_Y = test_Y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0)\n"
     ]
    }
   ],
   "source": [
    "train_x_split = np.array([[]*10])\n",
    "print(train_x_split.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_training_set(train_x, train_y):\n",
    "    train_x_split = [[] for _ in range(10)]\n",
    "    for i in range(len(train_y)):\n",
    "        train_x_split[train_y[i]].append(train_x[i])\n",
    "    return train_x_split\n",
    "\n",
    "def train_baysianGMM(train_x, train_y, k):\n",
    "    gmms = []\n",
    "    d = len(train_x[0])\n",
    "\n",
    "    train_x_by_classes = split_training_set(train_x, train_y)\n",
    "\n",
    "    # Calculate P(Y=c)\n",
    "    total = len(train_x)\n",
    "    P_yc = []\n",
    "    for x_c in train_x_by_classes:\n",
    "        P_yc.append(len(x_c)/total)\n",
    "\n",
    "    print(\"------- Training ------\")\n",
    "    # Train gmm for each class\n",
    "    for c in tqdm(range(len(train_x_by_classes))):\n",
    "        train_x_class_c = np.array(train_x_by_classes[c])\n",
    "        gmm_c = GMM(k, d)\n",
    "        gmm_c.EM(train_x_class_c)\n",
    "        gmms.append(gmm_c)\n",
    "\n",
    "    return gmms, P_yc\n",
    "\n",
    "def baysianGMM_classifier(x, gmms, P_yc):\n",
    "    largest_prob = -1\n",
    "    chosen_c = -1\n",
    "    for c in range(len(gmms)):\n",
    "        gmm_c = gmms[c]\n",
    "        prob = gmm_c.posterior(x) * P_yc[c]\n",
    "        if prob > largest_prob:\n",
    "            largest_prob = prob\n",
    "            chosen_c = c\n",
    "    \n",
    "    return chosen_c\n",
    "\n",
    "def report_test_err(test_X, test_Y, gmms, P_yc):\n",
    "    pred_Y = []\n",
    "    print(\"------- Testing ------\")\n",
    "    for x in tqdm(test_X):\n",
    "        y_hat = baysianGMM_classifier(x, gmms, P_yc)\n",
    "        pred_Y.append(y_hat)\n",
    "\n",
    "    err_count = 0\n",
    "    for y_hat, y in zip(pred_Y, test_Y):\n",
    "        if y_hat != y:\n",
    "            err_count += 1\n",
    "    \n",
    "    return err_count/len(test_Y)\n",
    "\n",
    "def train_and_test(train_data, train_label, test_data, test_label):\n",
    "    err_list = []\n",
    "    for k in (range(1, 11)):\n",
    "        print(\"============= Train and Test for k =\", k, \"===============\")\n",
    "        gmms, p_yc= train_baysianGMM(train_data, train_label, k)\n",
    "        err = report_test_err(test_data, test_label, gmms, p_yc)\n",
    "        err_list.append(err)\n",
    "        print(\"For k=\", k, \"Error is:\", err)\n",
    "\n",
    "\n",
    "    return err_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Training ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.69it/s]\n"
     ]
    }
   ],
   "source": [
    "# train_and_test(train_data_reduced, train_Y, test_data_reduced, test_Y)\n",
    "gmms, p_yc= train_baysianGMM(train_data_reduced, train_Y, 5)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Train and Test for k = 1 ===============\n",
      "------- Training ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 149.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Testing ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:01<00:00, 7998.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k= 1 Error is: 0.1247\n",
      "============= Train and Test for k = 2 ===============\n",
      "------- Training ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 15.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Testing ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:02<00:00, 4074.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k= 2 Error is: 0.1123\n",
      "============= Train and Test for k = 3 ===============\n",
      "------- Training ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  9.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Testing ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:03<00:00, 2705.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k= 3 Error is: 0.0921\n",
      "============= Train and Test for k = 4 ===============\n",
      "------- Training ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  7.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Testing ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:04<00:00, 2048.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k= 4 Error is: 0.0895\n",
      "============= Train and Test for k = 5 ===============\n",
      "------- Training ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Testing ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:06<00:00, 1658.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k= 5 Error is: 0.0859\n",
      "============= Train and Test for k = 6 ===============\n",
      "------- Training ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Testing ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:07<00:00, 1384.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k= 6 Error is: 0.0783\n",
      "============= Train and Test for k = 7 ===============\n",
      "------- Training ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Testing ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:08<00:00, 1198.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k= 7 Error is: 0.0764\n",
      "============= Train and Test for k = 8 ===============\n",
      "------- Training ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Testing ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:09<00:00, 1047.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k= 8 Error is: 0.0717\n",
      "============= Train and Test for k = 9 ===============\n",
      "------- Training ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Testing ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:10<00:00, 931.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k= 9 Error is: 0.0692\n",
      "============= Train and Test for k = 10 ===============\n",
      "------- Training ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Testing ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:11<00:00, 838.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k= 10 Error is: 0.0684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "err_list = train_and_test(train_data_reduced, train_Y, test_data_reduced, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1f8e04c1004ae0e48c4c128aee02bb34a41f967cffe60616a1dbeccdbed98bf0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
